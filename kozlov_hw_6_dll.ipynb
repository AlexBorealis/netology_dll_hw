{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MIEGXF8oM9tt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-YlRH3mQM9tf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "colab_type": "code",
        "id": "8UKlPFcBNZl5",
        "outputId": "c4eb79b7-0097-427e-f25c-a5f5e9473449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip rus-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mv rus.txt eng-rus.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "twIcAJnyRkW-",
        "outputId": "aae61acf-df6c-4443-8eaa-61a0be531bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "It's so easy to write good example sentences, that even if we accidentally delete a few good sentences in the process of getting rid of a whole lot of bad ones, I think we could drastically improve the quality of this corpus by doing a lot of deleting.\tСоздавать хорошие предложения-примеры так легко, что даже если мы случайно удалим несколько хороших предложений в процессе избавления от кучи плохих, думаю, мы могли бы заметно улучшить качество этого корпуса, удаляя в больших количествах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #933897 (CK) & #3689230 (Ooneykcall)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ],
      "source": [
        "!tail eng-rus.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kyNnJyruM9t1"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FXKs8j4bM9t6"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    parts = s.split('\\t')[:2]\n",
        "\n",
        "    result = []\n",
        "    for part in parts:\n",
        "        normalized = unicodedata.normalize('NFC', part)\n",
        "        result.append(normalized)\n",
        "        \n",
        "    return '\\t'.join(result)\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Zа-яА-Яйё.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Go.\\tМарш!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)',\n",
              " 'Go.\\tИди.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898247 (marafon)']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('eng-rus.txt', encoding='utf-8') as f:\n",
        "    text = f.read().strip().split('\\n')\n",
        "\n",
        "text[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D8T4VxZeM9t-"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eBOwgEBdM9uB"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "colab_type": "code",
        "id": "6dZOGjd5M9uE",
        "outputId": "0cdd3a7f-2ac8-4872-8a81-6101d0bdd0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 519900 sentence pairs\n",
            "Trimmed to 30087 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 10529\n",
            "eng 4377\n",
            "['я не занимаюсь .', 'i am not studying .']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m9vm9QBWM9uI"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, model_type=\"GRU\"):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        if model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = embedded\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size=1):\n",
        "        if self.model_type == \"LSTM\":\n",
        "            return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PFbuUL1LM9uL"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1, model_type=\"GRU\"):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        if model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output = self.softmax(self.out(output.squeeze(1)))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size=1):\n",
        "        if self.model_type == \"LSTM\":\n",
        "            return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z6gGPtXFM9uQ"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8Fn8VDv8M9uS"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    batch_size = input_tensor.size(0)\n",
        "    encoder_hidden = encoder.initHidden(batch_size)\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(1)\n",
        "    target_length = target_tensor.size(1)\n",
        "\n",
        "    encoder_outputs = torch.zeros(batch_size, max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[:, ei, :], encoder_hidden)\n",
        "        encoder_outputs[:, ei, :] = encoder_output.squeeze(1)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]] * batch_size, device=device).view(batch_size, 1)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[:, di, :].squeeze(1))\n",
        "            decoder_input = target_tensor[:, di, :] # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.detach() # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[:, di, :].squeeze(1))\n",
        "            if (decoder_input == EOS_token).any():\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EKsdwPmSM9uU"
      },
      "outputs": [],
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0JXG-RzCM9uZ"
      },
      "outputs": [],
      "source": [
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "def showPlot(points, name):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.savefig(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C_z_k5IiM9uX"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, name, batch_size=8, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for _ in range(n_iters)]\n",
        "    input_tensors = nn.utils.rnn.pad_sequence([pair[0] for pair in training_pairs], batch_first=True, padding_value=0)\n",
        "    target_tensors = nn.utils.rnn.pad_sequence([pair[1] for pair in training_pairs], batch_first=True, padding_value=0)\n",
        "    dataset = TensorDataset(input_tensors, target_tensors)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "    iter_count = 0\n",
        "\n",
        "    for _ in range(1, (n_iters // batch_size) + 1):\n",
        "        for batch_input, batch_target in dataloader:\n",
        "            if iter_count >= n_iters:\n",
        "                break\n",
        "\n",
        "            loss = train(batch_input, batch_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "            print_loss_total += loss * batch_input.size(0)\n",
        "            plot_loss_total += loss * batch_input.size(0)\n",
        "            iter_count += batch_input.size(0)\n",
        "\n",
        "            if iter_count % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter_count / n_iters), iter_count, iter_count / n_iters * 100, print_loss_avg))\n",
        "\n",
        "            if iter_count % plot_every == 0:\n",
        "                plot_loss_avg = plot_loss_total / plot_every\n",
        "                plot_losses.append(plot_loss_avg)\n",
        "                plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3Bxf45h6M9ud"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_tensor = input_tensor.view(1, -1, 1)\n",
        "        input_length = input_tensor.size(1)\n",
        "\n",
        "        encoder_hidden = encoder.initHidden(batch_size=1)\n",
        "\n",
        "        encoder_outputs = torch.zeros(1, max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[:, ei, :], encoder_hidden)\n",
        "            encoder_outputs[:, ei, :] = encoder_output.squeeze(1)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device).view(1, 1)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            _, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.view(1, 1).detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1qUmQIGwM9uf"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "colab_type": "code",
        "id": "s_56t10oM9uh",
        "outputId": "f456b0b8-fc35-4199-fb19-b45c2330bf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1m 3s (- 14m 48s) (5000 6%) 2.5891\n",
            "2m 3s (- 13m 21s) (10000 13%) 2.1628\n",
            "3m 3s (- 12m 13s) (15000 20%) 1.9841\n",
            "4m 3s (- 11m 8s) (20000 26%) 1.8442\n",
            "5m 2s (- 10m 4s) (25000 33%) 1.7299\n",
            "5m 59s (- 8m 58s) (30000 40%) 1.6447\n",
            "6m 55s (- 7m 55s) (35000 46%) 1.5458\n",
            "7m 53s (- 6m 54s) (40000 53%) 1.4774\n",
            "8m 51s (- 5m 54s) (45000 60%) 1.4263\n",
            "9m 51s (- 4m 55s) (50000 66%) 1.3675\n",
            "10m 51s (- 3m 56s) (55000 73%) 1.3051\n",
            "11m 50s (- 2m 57s) (60000 80%) 1.2745\n",
            "12m 50s (- 1m 58s) (65000 86%) 1.2015\n",
            "13m 50s (- 0m 59s) (70000 93%) 1.1740\n",
            "14m 50s (- 0m 0s) (75000 100%) 1.1310\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 1\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, batch_size=batch_size, print_every=5000, name='GRU_1_layer.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xEoEylSyM9uj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> я очень благодарен .\n",
            "= i m very grateful .\n",
            "< i m very grateful to be about . <EOS>\n",
            "\n",
            "> ты красивая .\n",
            "= you re beautiful .\n",
            "< you are beautiful beautiful beautiful beautiful . <EOS>\n",
            "\n",
            "> он пользуется любовью его людей .\n",
            "= he is popular with his men .\n",
            "< he s really his his his . <EOS>\n",
            "\n",
            "> я сегодня возвращаюсь в бостон .\n",
            "= i m going back to boston today .\n",
            "< i m going to boston to boston . SOS SOS\n",
            "\n",
            "> он умён и привлекателен .\n",
            "= he s intelligent and good looking .\n",
            "< he s really and and and and . <EOS>\n",
            "\n",
            "> я готовлюсь .\n",
            "= i m getting ready .\n",
            "< i m getting ready to . <EOS>\n",
            "\n",
            "> вы очень прямолинейны .\n",
            "= you re very direct .\n",
            "< you re very very very very you . <EOS>\n",
            "\n",
            "> прости что наорала на тебя .\n",
            "= i m sorry i yelled at you .\n",
            "< i m sorry i yelled at you . <EOS>\n",
            "\n",
            "> я не очень уверен насчёт тома .\n",
            "= i m not so sure about tom .\n",
            "< i m not sure about tom tom . <EOS>\n",
            "\n",
            "> я повариха .\n",
            "= i m a cook .\n",
            "< i m on a my book . . <EOS>\n",
            "\n",
            "> вы достаточно взрослая чтобы это понимать .\n",
            "= you are old enough to understand this .\n",
            "< you re old enough to do this . <EOS>\n",
            "\n",
            "> вы ведёте себя как дурак .\n",
            "= you re acting like a fool .\n",
            "< you re acting like a fool . <EOS>\n",
            "\n",
            "> со мной обращаются как с преступником .\n",
            "= i m being treated like a criminal .\n",
            "< i m being like a father . <EOS>\n",
            "\n",
            "> я не собираюсь на тебе жениться .\n",
            "= i m not going to marry you .\n",
            "< i m not going to marry you . <EOS>\n",
            "\n",
            "> я хороший .\n",
            "= i am good .\n",
            "< i m still good good . . <EOS>\n",
            "\n",
            "> я завтра женюсь .\n",
            "= i m getting married tomorrow .\n",
            "< i m getting married to australia tomorrow . <EOS>\n",
            "\n",
            "> я отлично провожу время .\n",
            "= i m having a great time .\n",
            "< i m just busy time time . <EOS>\n",
            "\n",
            "> мы в следующем месяце переезжаем .\n",
            "= we are moving next month .\n",
            "< we re moving next month . <EOS>\n",
            "\n",
            "> я пойду за мороженым .\n",
            "= i m going to get ice cream .\n",
            "< i m going to do next next year . <EOS>\n",
            "\n",
            "> я женюсь в октябре .\n",
            "= i m getting married in october .\n",
            "< i m getting married to australia . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, decoder1, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **The RNN with 2 GRU layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0m 55s (- 12m 57s) (5000 6%) 3.1578\n",
            "1m 49s (- 11m 52s) (10000 13%) 2.6981\n",
            "2m 41s (- 10m 45s) (15000 20%) 2.4538\n",
            "3m 34s (- 9m 48s) (20000 26%) 2.2457\n",
            "4m 26s (- 8m 53s) (25000 33%) 2.0903\n",
            "5m 19s (- 7m 59s) (30000 40%) 1.9685\n",
            "6m 13s (- 7m 7s) (35000 46%) 1.8434\n",
            "7m 10s (- 6m 16s) (40000 53%) 1.7107\n",
            "8m 6s (- 5m 24s) (45000 60%) 1.6267\n",
            "9m 2s (- 4m 31s) (50000 66%) 1.5722\n",
            "9m 58s (- 3m 37s) (55000 73%) 1.4471\n",
            "10m 55s (- 2m 43s) (60000 80%) 1.4022\n",
            "11m 51s (- 1m 49s) (65000 86%) 1.3500\n",
            "12m 47s (- 0m 54s) (70000 93%) 1.2782\n",
            "13m 45s (- 0m 0s) (75000 100%) 1.2218\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 1\n",
        "encoder2 = EncoderRNN(input_lang.n_words, hidden_size, num_layers=2).to(device)\n",
        "decoder2 = DecoderRNN(hidden_size, output_lang.n_words, num_layers=2).to(device)\n",
        "\n",
        "trainIters(encoder2, decoder2, 75000, batch_size=batch_size, print_every=5000, name='GRU_2_layer.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> мы отмечаем юбилей .\n",
            "= we re celebrating our anniversary .\n",
            "< we re making . <EOS>\n",
            "\n",
            "> прошу прощения что так опоздал .\n",
            "= i m sorry that i m so late .\n",
            "< i m sorry that i m so late . <EOS>\n",
            "\n",
            "> мне восемнадцать лет .\n",
            "= i m eighteen .\n",
            "< i m old . <EOS>\n",
            "\n",
            "> она в отчаянии .\n",
            "= she s desperate .\n",
            "< she s wearing . <EOS>\n",
            "\n",
            "> я уверен что у вас были добрые намерения .\n",
            "= i m sure you meant well .\n",
            "< i m sure your intentions you re good . <EOS>\n",
            "\n",
            "> я не такой ленивый как том .\n",
            "= i m not as lazy as tom .\n",
            "< i m not as lucky as tom is . <EOS>\n",
            "\n",
            "> боюсь ты опоздал .\n",
            "= i m afraid you re too late .\n",
            "< i m afraid you re so naive . <EOS>\n",
            "\n",
            "> ты ревнуешь .\n",
            "= you re jealous .\n",
            "< you re the . <EOS>\n",
            "\n",
            "> вы идёте на вечеринку .\n",
            "= you re going to a party .\n",
            "< you re our our . . <EOS>\n",
            "\n",
            "> я не пытаюсь произвести на тебя впечатление .\n",
            "= i m not trying to impress you .\n",
            "< i m not trying to impress you . <EOS>\n",
            "\n",
            "> у меня аллергия на кошек .\n",
            "= i m allergic to cats .\n",
            "< i m allergic to . <EOS>\n",
            "\n",
            "> я придерживаюсь своего плана .\n",
            "= i m sticking with my plan .\n",
            "< i m making my patience . <EOS>\n",
            "\n",
            "> ты ведь в этом уверена ?\n",
            "= you re sure about this right ?\n",
            "< you re sure about this right ? <EOS>\n",
            "\n",
            "> я пытаюсь экономить деньги .\n",
            "= i m trying to save money .\n",
            "< i m trying to be trying to <EOS>\n",
            "\n",
            "> она беспокоится о вашем здоровье .\n",
            "= she is anxious about your health .\n",
            "< she s anxious about your health . <EOS>\n",
            "\n",
            "> я думаю поехать за границу .\n",
            "= i am thinking of going abroad .\n",
            "< i m thinking of going to <EOS>\n",
            "\n",
            "> прошу прощения что побеспокоила .\n",
            "= i m sorry to have bothered you .\n",
            "< i m sorry . i m . <EOS>\n",
            "\n",
            "> я второкурсник .\n",
            "= i m a sophomore .\n",
            "< i m going . <EOS>\n",
            "\n",
            "> ты меня с кем то путаешь .\n",
            "= you re confusing me with somebody else .\n",
            "< you re telling with me with me . <EOS>\n",
            "\n",
            "> мы идём обратно .\n",
            "= we re going back .\n",
            "< we re going back . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder2, decoder2, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **The RNN with 2 GRU layers with batches**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1m 12s (- 10m 48s) (30000 10%) 2.3166\n",
            "2m 4s (- 8m 18s) (60000 20%) 1.8679\n",
            "2m 57s (- 6m 53s) (90000 30%) 1.6661\n",
            "3m 50s (- 5m 45s) (120000 40%) 1.5450\n",
            "4m 43s (- 4m 43s) (150000 50%) 1.4353\n",
            "5m 35s (- 3m 43s) (180000 60%) 1.3369\n",
            "6m 27s (- 2m 46s) (210000 70%) 1.2496\n",
            "7m 20s (- 1m 50s) (240000 80%) 1.1795\n",
            "8m 13s (- 0m 54s) (270000 90%) 1.1099\n",
            "9m 5s (- 0m 0s) (300000 100%) 1.0406\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 8\n",
        "encoder3 = EncoderRNN(input_lang.n_words, hidden_size, num_layers=2).to(device)\n",
        "decoder3 = DecoderRNN(hidden_size, output_lang.n_words, num_layers=2).to(device)\n",
        "\n",
        "trainIters(encoder3, decoder3, 300000, batch_size=batch_size, print_every=30000, name='GRU_2_layer_with_batches.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> я рада что с томом всё хорошо .\n",
            "= i m glad tom is ok .\n",
            "< i m glad tom is still here . <EOS>\n",
            "\n",
            "> я ревнивый .\n",
            "= i m jealous .\n",
            "< i m the same i in my class . <EOS>\n",
            "\n",
            "> я в поезде .\n",
            "= i m on the train .\n",
            "< i m in boston in this room . <EOS>\n",
            "\n",
            "> я просто за тебя беспокоюсь .\n",
            "= i m just worried about you .\n",
            "< i m just worried about what happened . <EOS>\n",
            "\n",
            "> мы все счастливы помочь .\n",
            "= we are all happy to help .\n",
            "< we re all trying to help tom . <EOS>\n",
            "\n",
            "> я найду тебя .\n",
            "= i m going to find you .\n",
            "< i m going to miss you a lot . <EOS>\n",
            "\n",
            "> не уверен что вам это понравится .\n",
            "= i m not sure you ll like it .\n",
            "< i m not sure you can do that . <EOS>\n",
            "\n",
            "> я не планирую никуда сегодня идти .\n",
            "= i m not planning to go anywhere today .\n",
            "< i m not going to boston this week . <EOS>\n",
            "\n",
            "> вы очень грязные .\n",
            "= you re really dirty .\n",
            "< you re very very to be married . <EOS>\n",
            "\n",
            "> ты не дурак .\n",
            "= you re not stupid .\n",
            "< you re not a not but anymore . <EOS>\n",
            "\n",
            "> я просто не уверен .\n",
            "= i m just not sure .\n",
            "< i m just not sure of anything . <EOS>\n",
            "\n",
            "> она застенчивая .\n",
            "= she s timid .\n",
            "< she is a a her . <EOS>\n",
            "\n",
            "> простите я забыл как вас зовут .\n",
            "= i m sorry i forgot your name .\n",
            "< i m sorry i i can do you . <EOS>\n",
            "\n",
            "> я не собираюсь его продавать .\n",
            "= i m not going to sell it .\n",
            "< i m not going to go there today . <EOS>\n",
            "\n",
            "> ты опоздал на три часа .\n",
            "= you re three hours late .\n",
            "< you re three three your your . . <EOS>\n",
            "\n",
            "> я за .\n",
            "= i m for that .\n",
            "< i m the for this for this . <EOS>\n",
            "\n",
            "> я не уверен что могу тебе помочь .\n",
            "= i m not sure i can help you .\n",
            "< i m not sure i can help you . <EOS>\n",
            "\n",
            "> ты шутишь не так ли ?\n",
            "= you re joking aren t you ?\n",
            "< you re not a are you are you ? <EOS>\n",
            "\n",
            "> вы вечно заняты .\n",
            "= you re always busy .\n",
            "< you re just pretty pretty of us . <EOS>\n",
            "\n",
            "> я не пьян .\n",
            "= i m not drunk .\n",
            "< i m not not that either . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder3, decoder3, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **The RNN with 2 LSTM layers with batches**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1m 17s (- 11m 37s) (30000 10%) 2.4427\n",
            "2m 15s (- 9m 3s) (60000 20%) 1.9160\n",
            "3m 12s (- 7m 30s) (90000 30%) 1.7427\n",
            "4m 11s (- 6m 16s) (120000 40%) 1.6024\n",
            "5m 8s (- 5m 8s) (150000 50%) 1.5116\n",
            "6m 7s (- 4m 4s) (180000 60%) 1.3970\n",
            "7m 6s (- 3m 2s) (210000 70%) 1.3091\n",
            "8m 5s (- 2m 1s) (240000 80%) 1.2196\n",
            "9m 4s (- 1m 0s) (270000 90%) 1.1468\n",
            "10m 2s (- 0m 0s) (300000 100%) 1.0785\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 8\n",
        "encoder4 = EncoderRNN(input_lang.n_words, hidden_size, num_layers=2, model_type=\"LSTM\").to(device)\n",
        "decoder4 = DecoderRNN(hidden_size, output_lang.n_words, num_layers=2, model_type=\"LSTM\").to(device)\n",
        "\n",
        "trainIters(encoder4, decoder4, 300000, batch_size=batch_size, print_every=30000, name='LSTM_2_layer_with_batches.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> она вдруг потеряла сознание .\n",
            "= she suddenly lost consciousness .\n",
            "< she is at her her . <EOS>\n",
            "\n",
            "> счастлив за вас обоих .\n",
            "= i m happy for you both .\n",
            "< i m happy about you with tom . <EOS>\n",
            "\n",
            "> прости что заставил тебя ждать .\n",
            "= i m sorry that i made you wait .\n",
            "< i m sorry that you have tom . <EOS>\n",
            "\n",
            "> я пошла обратно работать .\n",
            "= i m going back to work .\n",
            "< i m going to boston for this . <EOS>\n",
            "\n",
            "> мы лучше всех .\n",
            "= we re the best .\n",
            "< we re thinking and what i can . <EOS>\n",
            "\n",
            "> я не специалист .\n",
            "= i m not an expert .\n",
            "< i m not at this with tom . <EOS>\n",
            "\n",
            "> ты странная .\n",
            "= you re weird .\n",
            "< you re free with i can you . <EOS>\n",
            "\n",
            "> я ем огурец .\n",
            "= i m eating a cucumber .\n",
            "< i m good at french . <EOS>\n",
            "\n",
            "> он боится своего отца .\n",
            "= he is afraid of his father .\n",
            "< he is sure of his his mother . <EOS>\n",
            "\n",
            "> мы сыты по горло коррупцией в государстве .\n",
            "= we are sick and tired of political corruption .\n",
            "< we re tired of of your room . <EOS>\n",
            "\n",
            "> рада за тебя .\n",
            "= i m happy for you .\n",
            "< i m thinking to do that you . <EOS>\n",
            "\n",
            "> я устала ждать .\n",
            "= i m tired of waiting .\n",
            "< i m tired of your new . <EOS>\n",
            "\n",
            "> простите что я в вас выстрелил .\n",
            "= i m sorry i shot you .\n",
            "< i m sorry i i have you . <EOS>\n",
            "\n",
            "> я не только о томе говорю .\n",
            "= i m not talking about just tom .\n",
            "< i m not worried about tom s tom . <EOS>\n",
            "\n",
            "> вы готовы .\n",
            "= you re ready .\n",
            "< you re thinking about what i can . <EOS>\n",
            "\n",
            "> он всё время смеётся .\n",
            "= he is always laughing .\n",
            "< he is always in in the same . <EOS>\n",
            "\n",
            "> ты забавная .\n",
            "= you re fun .\n",
            "< you re free and i can you . <EOS>\n",
            "\n",
            "> я не могу перевести это предложение .\n",
            "= i m unable to translate this sentence .\n",
            "< i m not sure of this s . <EOS>\n",
            "\n",
            "> ты подлый лжец .\n",
            "= you re a filthy liar .\n",
            "< you re free and i think . <EOS>\n",
            "\n",
            "> рад за тебя .\n",
            "= i m happy for you .\n",
            "< i m thinking for you to that . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder4, decoder4, n=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Лекция 8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
